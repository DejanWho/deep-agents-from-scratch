{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aabb159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(os.path.join(\"..\", \".env\"), override=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a407e4",
   "metadata": {},
   "source": [
    "## Context Offloading: Filesystem\n",
    "\n",
    "<img src=\"./assets/agent_header_files.png\" width=\"800\" style=\"display:block; margin-left:0;\">\n",
    "\n",
    "Agent context windows can grow rapidly during complex tasks—the average Manus task uses approximately 50 tool calls, creating substantial context accumulation. A powerful technique for managing this growth is **context offloading** through filesystem operations. Rather than storing all tool call observations and intermediate results directly in the context window, agents can strategically save information to files and [fetch it as-needed](https://blog.langchain.com/context-engineering-for-agents/), maintaining focus while preserving access to critical information.\n",
    "\n",
    "This approach has been successfully implemented by production systems like [Manus](https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus) and [Hugging Face Open Deep Research](https://huggingface.co/blog/open-deep-research). Anthropic's [multi-agent research system](https://www.anthropic.com/engineering/multi-agent-research-system#:~:text=Subagent%20output%20to%20a%20filesystem%20to%20minimize%20the%20%E2%80%98game%20of%20telephone.%E2%80%99) provides another compelling example, where subagents store their work in external systems and pass lightweight references back to coordinators. This prevents the \"game of telephone\" effect—information degradation as it passes through multiple agents—while enabling fresh subagents to spawn with clean contexts and retrieve stored context like research plans from memory when needed.\n",
    "\n",
    "By writing token-heavy context to files in sandboxed environments, agents can effectively manage memory while maintaining the ability to retrieve detailed information when necessary. This pattern is particularly valuable for structured outputs like code, reports, or data visualizations where specialized prompts produce better results than filtering through general coordinators, and for long-running research tasks where intermediate results need preservation without constant attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9854e27-f800-4563-9ed1-82837039cf97",
   "metadata": {},
   "source": [
    "### File Tools\n",
    "\n",
    "Our implementation uses a virtual filesystem approach that mocks the traditional filesystem within LangGraph state. The core insight is to use a simple dictionary where keys represent mock file paths and values contain the file content. This approach provides short-term, thread-wise persistence that's ideal for maintaining context within a single agent conversation, though it's not suited for information that needs to persist across different conversation threads. The file operations utilize LangGraph's `Command` type to update the agent state, enabling tools to modify the virtual filesystem and maintain proper state management throughout the agent's execution.\n",
    "\n",
    "You’ll build three file tools—`ls`, `read_file`, and `write_file`—that operate on the virtual file system.\n",
    "\n",
    "**Usage:** \n",
    "- When the LLM has information in its context that it wants to persist, it writes it to a file with `write_file`; later, the same agent or a subagent can retrieve it with `read_file`.\n",
    "- A tool call can write data to a file and provide the filename in the tool call return message to the LLM. The LLM can later decide to read some or all of the content, or could apply another tool to process the data. \n",
    "- Use `ls` to list available files.\n",
    "\n",
    "The read/write tools expect newline-delimited plain text (parsed with `str.splitlines()`).\n",
    "\n",
    "\n",
    "The descriptions in the prompts below describe in detail how they operate:"
   ]
  },
  {
   "cell_type": "code",
   "id": "abe282a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T16:39:52.091221Z",
     "start_time": "2025-09-21T16:39:52.017475Z"
    }
   },
   "source": [
    "from utils import show_prompt\n",
    "\n",
    "from src.deep_agents_from_scratch.prompts import (\n",
    "    LS_DESCRIPTION,\n",
    "    READ_FILE_DESCRIPTION,\n",
    "    WRITE_FILE_DESCRIPTION,\n",
    ")\n",
    "\n",
    "show_prompt(LS_DESCRIPTION)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[34m╭─\u001B[0m\u001B[34m───────────────────────────────────────────────────\u001B[0m\u001B[34m \u001B[0m\u001B[1;32mPrompt\u001B[0m\u001B[34m \u001B[0m\u001B[34m────────────────────────────────────────────────────\u001B[0m\u001B[34m─╮\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  List all files in the virtual filesystem stored in agent state.                                                \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  Shows what files currently exist in agent memory. Use this to orient yourself before other file operations     \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  and maintain awareness of your file organization.                                                              \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  No parameters required - simply call ls() to see all available files.                                          \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  List all files in the virtual filesystem stored in agent state.                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Shows what files currently exist in agent memory. Use this to orient yourself before other file operations     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  and maintain awareness of your file organization.                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  No parameters required - simply call ls() to see all available files.                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "8dc7bb26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T16:39:54.850460Z",
     "start_time": "2025-09-21T16:39:54.842575Z"
    }
   },
   "source": [
    "show_prompt(READ_FILE_DESCRIPTION)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[34m╭─\u001B[0m\u001B[34m───────────────────────────────────────────────────\u001B[0m\u001B[34m \u001B[0m\u001B[1;32mPrompt\u001B[0m\u001B[34m \u001B[0m\u001B[34m────────────────────────────────────────────────────\u001B[0m\u001B[34m─╮\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  Read content from a file in the virtual filesystem with optional pagination.                                   \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  This tool returns file content with line numbers (like `cat -n`) and supports reading large files in chunks    \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  to avoid context overflow.                                                                                     \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  Parameters:                                                                                                    \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  - file_path (required): Path to the file you want to read                                                      \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  - offset (optional, default=0): Line number to start reading from                                              \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  - limit (optional, default=2000): Maximum number of lines to read                                              \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  Essential before making any edits to understand existing content. Always read a file before editing it.        \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Read content from a file in the virtual filesystem with optional pagination.                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  This tool returns file content with line numbers (like `cat -n`) and supports reading large files in chunks    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  to avoid context overflow.                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Parameters:                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - file_path (required): Path to the file you want to read                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - offset (optional, default=0): Line number to start reading from                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - limit (optional, default=2000): Maximum number of lines to read                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Essential before making any edits to understand existing content. Always read a file before editing it.        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "2de27788",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T16:39:59.361922Z",
     "start_time": "2025-09-21T16:39:59.354461Z"
    }
   },
   "source": [
    "show_prompt(WRITE_FILE_DESCRIPTION)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[34m╭─\u001B[0m\u001B[34m───────────────────────────────────────────────────\u001B[0m\u001B[34m \u001B[0m\u001B[1;32mPrompt\u001B[0m\u001B[34m \u001B[0m\u001B[34m────────────────────────────────────────────────────\u001B[0m\u001B[34m─╮\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  Create a new file or completely overwrite an existing file in the virtual filesystem.                          \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  This tool creates new files or replaces entire file contents. Use for initial file creation or complete        \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  rewrites. Files are stored persistently in agent state.                                                        \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  Parameters:                                                                                                    \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  - file_path (required): Path where the file should be created/overwritten                                      \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  - content (required): The complete content to write to the file                                                \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  Important: This replaces the entire file content.                                                              \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Create a new file or completely overwrite an existing file in the virtual filesystem.                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  This tool creates new files or replaces entire file contents. Use for initial file creation or complete        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  rewrites. Files are stored persistently in agent state.                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Parameters:                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - file_path (required): Path where the file should be created/overwritten                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - content (required): The complete content to write to the file                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Important: This replaces the entire file content.                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "6d581826",
   "metadata": {},
   "source": [
    "Let's implement these functions below. There are two items worth noting. The first is the use of `@tool(description=PROMPT)`. Note that when `description=\"xyz\" is in the tool decorator, \"xyz\" is sent to the LLM and the docstring is suppressed. It is often more convenient to have lengthy descriptions in a separate prompts file. This provides space to explain both the operation of the tool and how it should be used in this application. The second item is the error messages. These messages are intended for the LLM vs a human user. In an agentic system, the LLM can use the information in error messages to retry the operation. "
   ]
  },
  {
   "cell_type": "code",
   "id": "9b7f3968",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T16:40:05.451840Z",
     "start_time": "2025-09-21T16:40:05.442111Z"
    }
   },
   "source": [
    "%%writefile ../src/deep_agents_from_scratch/file_tools.py\n",
    "\"\"\"Virtual file system tools for agent state management.\n",
    "\n",
    "This module provides tools for managing a virtual filesystem stored in agent state,\n",
    "enabling context offloading and information persistence across agent interactions.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from langgraph.types import Command\n",
    "\n",
    "from src.deep_agents_from_scratch.prompts import (\n",
    "    LS_DESCRIPTION,\n",
    "    READ_FILE_DESCRIPTION,\n",
    "    WRITE_FILE_DESCRIPTION,\n",
    ")\n",
    "from src.deep_agents_from_scratch.state import DeepAgentState\n",
    "\n",
    "\n",
    "@tool(description=LS_DESCRIPTION)\n",
    "def ls(state: Annotated[DeepAgentState, InjectedState]) -> list[str]:\n",
    "    \"\"\"List all files in the virtual filesystem.\"\"\"\n",
    "    return list(state.get(\"files\", {}).keys())\n",
    "\n",
    "\n",
    "@tool(description=READ_FILE_DESCRIPTION, parse_docstring=True)\n",
    "def read_file(\n",
    "    file_path: str,\n",
    "    state: Annotated[DeepAgentState, InjectedState],\n",
    "    offset: int = 0,\n",
    "    limit: int = 2000,\n",
    ") -> str:\n",
    "    \"\"\"Read file content from virtual filesystem with optional offset and limit.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to the file to read\n",
    "        state: Agent state containing virtual filesystem (injected in tool node)\n",
    "        offset: Line number to start reading from (default: 0)\n",
    "        limit: Maximum number of lines to read (default: 2000)\n",
    "\n",
    "    Returns:\n",
    "        Formatted file content with line numbers, or error message if file not found\n",
    "    \"\"\"\n",
    "    files = state.get(\"files\", {})\n",
    "    if file_path not in files:\n",
    "        return f\"Error: File '{file_path}' not found\"\n",
    "\n",
    "    content = files[file_path]\n",
    "    if not content:\n",
    "        return \"System reminder: File exists but has empty contents\"\n",
    "\n",
    "    lines = content.splitlines()\n",
    "    start_idx = offset\n",
    "    end_idx = min(start_idx + limit, len(lines))\n",
    "\n",
    "    if start_idx >= len(lines):\n",
    "        return f\"Error: Line offset {offset} exceeds file length ({len(lines)} lines)\"\n",
    "\n",
    "    result_lines = []\n",
    "    for i in range(start_idx, end_idx):\n",
    "        line_content = lines[i][:2000]  # Truncate long lines\n",
    "        result_lines.append(f\"{i + 1:6d}\\t{line_content}\")\n",
    "\n",
    "    return \"\\n\".join(result_lines)\n",
    "\n",
    "\n",
    "@tool(description=WRITE_FILE_DESCRIPTION, parse_docstring=True)\n",
    "def write_file(\n",
    "    file_path: str,\n",
    "    content: str,\n",
    "    state: Annotated[DeepAgentState, InjectedState],\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId],\n",
    ") -> Command:\n",
    "    \"\"\"Write content to a file in the virtual filesystem.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path where the file should be created/updated\n",
    "        content: Content to write to the file\n",
    "        state: Agent state containing virtual filesystem (injected in tool node)\n",
    "        tool_call_id: Tool call identifier for message response (injected in tool node)\n",
    "\n",
    "    Returns:\n",
    "        Command to update agent state with new file content\n",
    "    \"\"\"\n",
    "    files = state.get(\"files\", {})\n",
    "    files[file_path] = content\n",
    "    return Command(\n",
    "        update={\n",
    "            \"files\": files,\n",
    "            \"messages\": [\n",
    "                ToolMessage(f\"Updated file {file_path}\", tool_call_id=tool_call_id)\n",
    "            ],\n",
    "        }\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/deep_agents_from_scratch/file_tools.py\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "d557741d-20c4-434e-b565-0dfd2729f7af",
   "metadata": {},
   "source": [
    "# Revisiting state and reducer \n",
    "In the previous notebook, we defined the file state and reducer, but did not describe them. Let's do that here.\n",
    "In `DeepAgentState`, `files` is defined as a dictionary with a key and value. As was mentioned above, the key is the filename and the value is the content of the file. `files` are added to state using the `file_reducer` when the `Command` in `write_files` is executed. In this reducer, `left` is the existing files in state and `right` is new values. The final statement allows the new values to overwrite old values: `{**left, **right}`, Python unpacks `left` first, then `right`. Any duplicate keys from `right` overwrite the earlier values from `left`.\n",
    "\n",
    "```python\n",
    "def file_reducer(left, right):\n",
    "    \"\"\"Merge two file dictionaries, with right side taking precedence.\n",
    "\n",
    "    Used as a reducer function for the files field in agent state,\n",
    "    allowing incremental updates to the virtual file system.\n",
    "\n",
    "    Args:\n",
    "        left: Left side dictionary (existing files)\n",
    "        right: Right side dictionary (new/updated files)\n",
    "\n",
    "    Returns:\n",
    "        Merged dictionary with right values overriding left values\n",
    "    \"\"\"\n",
    "    if left is None:\n",
    "        return right\n",
    "    elif right is None:\n",
    "        return left\n",
    "    else:\n",
    "        return {**left, **right}\n",
    "\n",
    "\n",
    "class DeepAgentState(AgentState):\n",
    "    \"\"\"Extended agent state that includes task tracking and virtual file system.\n",
    "\n",
    "    Inherits from LangGraph's AgentState and adds:\n",
    "    - todos: List of Todo items for task planning and progress tracking\n",
    "    - files: Virtual file system stored as dict mapping filenames to content\n",
    "    \"\"\"\n",
    "\n",
    "    todos: NotRequired[list[Todo]]\n",
    "    files: Annotated[NotRequired[dict[str, str]], file_reducer]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a0a899",
   "metadata": {},
   "source": [
    "We have a virtual filesystem and tools to work with it.  Let's build a simple research agent to try it out. \n",
    "The agent will store the user's request and then read it back before answering the user's question! \n",
    "\n",
    "Note that this simple approach is [very useful with long-running agent trajectories](https://www.anthropic.com/engineering/multi-agent-research-system#:~:text=Long%2Dhorizon%20conversation,across%20extended%20interactions.)! In this simple example, all information is easily kept in context, but for long-running agents, context content can be compressed or eliminated. Storing information prior to compression and retrieving it when it's needed is smart context engineering."
   ]
  },
  {
   "cell_type": "code",
   "id": "b6a1ac50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T16:40:24.518189Z",
     "start_time": "2025-09-21T16:40:24.510404Z"
    }
   },
   "source": [
    "# File usage instructions\n",
    "FILE_USAGE_INSTRUCTIONS = \"\"\"You have access to a virtual file system to help you retain and save context.                                  \n",
    "                                                                                                                \n",
    "## Workflow Process                                                                                            \n",
    "1. **Orient**: Use ls() to see existing files before starting work                                             \n",
    "2. **Save**: Use write_file() to store the user's request so that we can keep it for later                     \n",
    "3. **Read**: Once you are satisfied with the collected sources, read the saved file and use it to ensure that you directly answer the user's question.\"\"\"\n",
    "\n",
    "# Add mock research instructions\n",
    "SIMPLE_RESEARCH_INSTRUCTIONS = \"\"\"IMPORTANT: Just make a single call to the web_search tool and use the result provided by the tool to answer the user's question.\"\"\"\n",
    "\n",
    "# Full prompt\n",
    "INSTRUCTIONS = (\n",
    "    FILE_USAGE_INSTRUCTIONS + \"\\n\\n\" + \"=\" * 80 + \"\\n\\n\" + SIMPLE_RESEARCH_INSTRUCTIONS\n",
    ")\n",
    "show_prompt(INSTRUCTIONS)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[34m╭─\u001B[0m\u001B[34m───────────────────────────────────────────────────\u001B[0m\u001B[34m \u001B[0m\u001B[1;32mPrompt\u001B[0m\u001B[34m \u001B[0m\u001B[34m────────────────────────────────────────────────────\u001B[0m\u001B[34m─╮\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  You have access to a virtual file system to help you retain and save context.                                  \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  \u001B[1;35m## Workflow Process                                                                                          \u001B[0m  \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  1. **Orient**: Use ls() to see existing files before starting work                                             \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  2. **Save**: Use write_file() to store the user's request so that we can keep it for later                     \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  3. **Read**: Once you are satisfied with the collected sources, read the saved file and use it to ensure that  \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  you directly answer the user's question.                                                                       \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  ================================================================================                               \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  IMPORTANT: Just make a single call to the web_search tool and use the result provided by the tool to answer    \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m  the user's question.                                                                                           \u001B[34m│\u001B[0m\n",
       "\u001B[34m│\u001B[0m                                                                                                                 \u001B[34m│\u001B[0m\n",
       "\u001B[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You have access to a virtual file system to help you retain and save context.                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Workflow Process                                                                                          </span>  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **Orient**: Use ls() to see existing files before starting work                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **Save**: Use write_file() to store the user's request so that we can keep it for later                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  3. **Read**: Once you are satisfied with the collected sources, read the saved file and use it to ensure that  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  you directly answer the user's question.                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  ================================================================================                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  IMPORTANT: Just make a single call to the web_search tool and use the result provided by the tool to answer    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  the user's question.                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "a94f78c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T16:40:30.166270Z",
     "start_time": "2025-09-21T16:40:29.305020Z"
    }
   },
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from utils import format_messages\n",
    "\n",
    "from src.deep_agents_from_scratch.file_tools import ls, read_file, write_file\n",
    "from src.deep_agents_from_scratch.state import DeepAgentState\n",
    "\n",
    "# Mock search result\n",
    "search_result = \"\"\"The Model Context Protocol (MCP) is an open standard protocol developed \n",
    "by Anthropic to enable seamless integration between AI models and external systems like \n",
    "tools, databases, and other services. It acts as a standardized communication layer, \n",
    "allowing AI models to access and utilize data from various sources in a consistent and \n",
    "efficient manner. Essentially, MCP simplifies the process of connecting AI assistants \n",
    "to external services by providing a unified language for data exchange. \"\"\"\n",
    "\n",
    "\n",
    "# Mock search tool\n",
    "@tool(parse_docstring=True)\n",
    "def web_search(\n",
    "    query: str,\n",
    "):\n",
    "    \"\"\"Search the web for information on a specific topic.\n",
    "\n",
    "    This tool performs web searches and returns relevant results\n",
    "    for the given query. Use this when you need to gather information from\n",
    "    the internet about any topic.\n",
    "\n",
    "    Args:\n",
    "        query: The search query string. Be specific and clear about what\n",
    "               information you're looking for.\n",
    "\n",
    "    Returns:\n",
    "        Search results from search engine.\n",
    "\n",
    "    Example:\n",
    "        web_search(\"machine learning applications in healthcare\")\n",
    "    \"\"\"\n",
    "    return search_result\n",
    "\n",
    "\n",
    "# Create agent using create_react_agent directly\n",
    "model = init_chat_model(model=\"anthropic:claude-sonnet-4-20250514\", temperature=0.0)\n",
    "tools = [ls, read_file, write_file, web_search]\n",
    "\n",
    "# Create agent with system prompt\n",
    "agent = create_react_agent(\n",
    "    model, tools, prompt=INSTRUCTIONS, state_schema=DeepAgentState\n",
    ")\n",
    "\n",
    "# Show the agent\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import langchain_anthropic. Please install with `pip install -U langchain-anthropic`",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 44\u001B[39m\n\u001B[32m     40\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m search_result\n\u001B[32m     43\u001B[39m \u001B[38;5;66;03m# Create agent using create_react_agent directly\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m44\u001B[39m model = \u001B[43minit_chat_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43manthropic:claude-sonnet-4-20250514\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     45\u001B[39m tools = [ls, read_file, write_file, web_search]\n\u001B[32m     47\u001B[39m \u001B[38;5;66;03m# Create agent with system prompt\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\cookbook\\Lib\\site-packages\\langchain\\chat_models\\base.py:322\u001B[39m, in \u001B[36minit_chat_model\u001B[39m\u001B[34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001B[39m\n\u001B[32m    315\u001B[39m     warnings.warn(\n\u001B[32m    316\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig_prefix\u001B[38;5;132;01m=}\u001B[39;00m\u001B[33m has been set but no fields are configurable. Set \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    317\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m`configurable_fields=(...)` to specify the model params that are \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    318\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mconfigurable.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    319\u001B[39m     )\n\u001B[32m    321\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m configurable_fields:\n\u001B[32m--> \u001B[39m\u001B[32m322\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_init_chat_model_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    323\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_provider\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_provider\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    324\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    325\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    326\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m model:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\cookbook\\Lib\\site-packages\\langchain\\chat_models\\base.py:347\u001B[39m, in \u001B[36m_init_chat_model_helper\u001B[39m\u001B[34m(model, model_provider, **kwargs)\u001B[39m\n\u001B[32m    345\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m ChatOpenAI(model=model, **kwargs)\n\u001B[32m    346\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m model_provider == \u001B[33m\"\u001B[39m\u001B[33manthropic\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m347\u001B[39m     \u001B[43m_check_pkg\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlangchain_anthropic\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    348\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_anthropic\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChatAnthropic\n\u001B[32m    350\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m ChatAnthropic(model=model, **kwargs)  \u001B[38;5;66;03m# type: ignore[call-arg,unused-ignore]\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\cookbook\\Lib\\site-packages\\langchain\\chat_models\\base.py:535\u001B[39m, in \u001B[36m_check_pkg\u001B[39m\u001B[34m(pkg, pkg_kebab)\u001B[39m\n\u001B[32m    533\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m util.find_spec(pkg):\n\u001B[32m    534\u001B[39m     pkg_kebab = pkg_kebab \u001B[38;5;28;01mif\u001B[39;00m pkg_kebab \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m pkg.replace(\u001B[33m\"\u001B[39m\u001B[33m_\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m-\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m535\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[32m    536\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mUnable to import \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpkg\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m. Please install with `pip install -U \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpkg_kebab\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m`\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    537\u001B[39m     )\n",
      "\u001B[31mImportError\u001B[39m: Unable to import langchain_anthropic. Please install with `pip install -U langchain-anthropic`"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "7054ebcc",
   "metadata": {},
   "source": [
    "Start the graph with no `files` in state and an user research request. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3e90ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────────────── 🧑 Human ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Give me an overview of Model Context Protocol (MCP).                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[34m╭─\u001B[0m\u001B[34m──────────────────────────────────────────────────\u001B[0m\u001B[34m 🧑 Human \u001B[0m\u001B[34m───────────────────────────────────────────────────\u001B[0m\u001B[34m─╮\u001B[0m\n",
       "\u001B[34m│\u001B[0m Give me an overview of Model Context Protocol (MCP).                                                            \u001B[34m│\u001B[0m\n",
       "\u001B[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> I'll help you get an overview of Model Context Protocol (MCP). Let me start by checking my current file system  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> and then search for information about MCP.                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: ls                                                                                                <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {}                                                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: toolu_01KNty5tCGQzaCqNF2ULRquC                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[37m╭─\u001B[0m\u001B[37m────────────────────────────────────────────────────\u001B[0m\u001B[37m 📝 AI \u001B[0m\u001B[37m────────────────────────────────────────────────────\u001B[0m\u001B[37m─╮\u001B[0m\n",
       "\u001B[37m│\u001B[0m I'll help you get an overview of Model Context Protocol (MCP). Let me start by checking my current file system  \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m and then search for information about MCP.                                                                      \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m                                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m 🔧 Tool Call: ls                                                                                                \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m    Args: {}                                                                                                     \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m    ID: toolu_01KNty5tCGQzaCqNF2ULRquC                                                                           \u001B[37m│\u001B[0m\n",
       "\u001B[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[33m╭─\u001B[0m\u001B[33m───────────────────────────────────────────────\u001B[0m\u001B[33m 🔧 Tool Output \u001B[0m\u001B[33m────────────────────────────────────────────────\u001B[0m\u001B[33m─╮\u001B[0m\n",
       "\u001B[33m│\u001B[0m                                                                                                                 \u001B[33m│\u001B[0m\n",
       "\u001B[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: write_file                                                                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"file_path\": \"user_request.txt\",                                                                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"content\": \"User Request: Give me an overview of Model Context Protocol (MCP).\\n\\nThe user wants a            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> comprehensive overview of Model Context Protocol, including what it is, its purpose, key features, and how it   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> works.\"                                                                                                         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: toolu_01ShZJgsTyM9uWJJnvXttPpE                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[37m╭─\u001B[0m\u001B[37m────────────────────────────────────────────────────\u001B[0m\u001B[37m 📝 AI \u001B[0m\u001B[37m────────────────────────────────────────────────────\u001B[0m\u001B[37m─╮\u001B[0m\n",
       "\u001B[37m│\u001B[0m                                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m 🔧 Tool Call: write_file                                                                                        \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m    Args: {                                                                                                      \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m   \"file_path\": \"user_request.txt\",                                                                              \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m   \"content\": \"User Request: Give me an overview of Model Context Protocol (MCP).\\n\\nThe user wants a            \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m comprehensive overview of Model Context Protocol, including what it is, its purpose, key features, and how it   \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m works.\"                                                                                                         \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m }                                                                                                               \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m    ID: toolu_01ShZJgsTyM9uWJJnvXttPpE                                                                           \u001B[37m│\u001B[0m\n",
       "\u001B[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Updated file user_request.txt                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[33m╭─\u001B[0m\u001B[33m───────────────────────────────────────────────\u001B[0m\u001B[33m 🔧 Tool Output \u001B[0m\u001B[33m────────────────────────────────────────────────\u001B[0m\u001B[33m─╮\u001B[0m\n",
       "\u001B[33m│\u001B[0m Updated file user_request.txt                                                                                   \u001B[33m│\u001B[0m\n",
       "\u001B[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: web_search                                                                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"query\": \"Model Context Protocol MCP overview what is it purpose features\"                                    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: toolu_01P4V5oXaH7yb4J43oopprqk                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[37m╭─\u001B[0m\u001B[37m────────────────────────────────────────────────────\u001B[0m\u001B[37m 📝 AI \u001B[0m\u001B[37m────────────────────────────────────────────────────\u001B[0m\u001B[37m─╮\u001B[0m\n",
       "\u001B[37m│\u001B[0m                                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m 🔧 Tool Call: web_search                                                                                        \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m    Args: {                                                                                                      \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m   \"query\": \"Model Context Protocol MCP overview what is it purpose features\"                                    \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m }                                                                                                               \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m    ID: toolu_01P4V5oXaH7yb4J43oopprqk                                                                           \u001B[37m│\u001B[0m\n",
       "\u001B[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The Model Context Protocol (MCP) is an open standard protocol developed                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> by Anthropic to enable seamless integration between AI models and external systems like                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> tools, databases, and other services. It acts as a standardized communication layer,                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> allowing AI models to access and utilize data from various sources in a consistent and                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> efficient manner. Essentially, MCP simplifies the process of connecting AI assistants                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> to external services by providing a unified language for data exchange.                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[33m╭─\u001B[0m\u001B[33m───────────────────────────────────────────────\u001B[0m\u001B[33m 🔧 Tool Output \u001B[0m\u001B[33m────────────────────────────────────────────────\u001B[0m\u001B[33m─╮\u001B[0m\n",
       "\u001B[33m│\u001B[0m The Model Context Protocol (MCP) is an open standard protocol developed                                         \u001B[33m│\u001B[0m\n",
       "\u001B[33m│\u001B[0m by Anthropic to enable seamless integration between AI models and external systems like                         \u001B[33m│\u001B[0m\n",
       "\u001B[33m│\u001B[0m tools, databases, and other services. It acts as a standardized communication layer,                            \u001B[33m│\u001B[0m\n",
       "\u001B[33m│\u001B[0m allowing AI models to access and utilize data from various sources in a consistent and                          \u001B[33m│\u001B[0m\n",
       "\u001B[33m│\u001B[0m efficient manner. Essentially, MCP simplifies the process of connecting AI assistants                           \u001B[33m│\u001B[0m\n",
       "\u001B[33m│\u001B[0m to external services by providing a unified language for data exchange.                                         \u001B[33m│\u001B[0m\n",
       "\u001B[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: read_file                                                                                         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"file_path\": \"user_request.txt\"                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: toolu_01UHFjiMbrboijJivWgNDSG3                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[37m╭─\u001B[0m\u001B[37m────────────────────────────────────────────────────\u001B[0m\u001B[37m 📝 AI \u001B[0m\u001B[37m────────────────────────────────────────────────────\u001B[0m\u001B[37m─╮\u001B[0m\n",
       "\u001B[37m│\u001B[0m                                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m 🔧 Tool Call: read_file                                                                                         \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m    Args: {                                                                                                      \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m   \"file_path\": \"user_request.txt\"                                                                               \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m }                                                                                                               \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m    ID: toolu_01UHFjiMbrboijJivWgNDSG3                                                                           \u001B[37m│\u001B[0m\n",
       "\u001B[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>      1  User Request: Give me an overview of Model Context Protocol (MCP).                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>      2                                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>      3  The user wants a comprehensive overview of Model Context Protocol, including what it is, its purpose,   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> key features, and how it works.                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[33m╭─\u001B[0m\u001B[33m───────────────────────────────────────────────\u001B[0m\u001B[33m 🔧 Tool Output \u001B[0m\u001B[33m────────────────────────────────────────────────\u001B[0m\u001B[33m─╮\u001B[0m\n",
       "\u001B[33m│\u001B[0m      1  User Request: Give me an overview of Model Context Protocol (MCP).                                      \u001B[33m│\u001B[0m\n",
       "\u001B[33m│\u001B[0m      2                                                                                                          \u001B[33m│\u001B[0m\n",
       "\u001B[33m│\u001B[0m      3  The user wants a comprehensive overview of Model Context Protocol, including what it is, its purpose,   \u001B[33m│\u001B[0m\n",
       "\u001B[33m│\u001B[0m key features, and how it works.                                                                                 \u001B[33m│\u001B[0m\n",
       "\u001B[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Based on my search, here's a comprehensive overview of Model Context Protocol (MCP):                            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> ## What is Model Context Protocol (MCP)?                                                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Model Context Protocol (MCP) is an **open standard protocol** developed by Anthropic that serves as a           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> standardized communication layer between AI models and external systems. It's designed to enable seamless       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> integration and data exchange between AI assistants and various external services.                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> ## Key Purpose                                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> MCP addresses a fundamental challenge in AI development: **connecting AI models to external data sources and    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> tools**. Instead of building custom integrations for each service, MCP provides a unified framework that allows <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> AI models to:                                                                                                   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - Access databases                                                                                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - Interact with APIs                                                                                            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - Use external tools and services                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - Retrieve information from various data sources                                                                <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> ## How It Works                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> MCP acts as a **bridge or translation layer** that:                                                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 1. **Standardizes Communication**: Provides a consistent language and protocol for data exchange                <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 2. **Simplifies Integration**: Eliminates the need for custom connectors for each external service              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 3. **Enables Interoperability**: Allows different AI systems to work with the same external resources using the <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> same protocol                                                                                                   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> ## Key Benefits                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - **Consistency**: One protocol to rule them all - no need to learn different APIs for each service             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - **Efficiency**: Streamlined data access and tool usage for AI models                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - **Scalability**: Easy to add new services and tools without rebuilding integrations                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - **Open Standard**: Being open-source, it promotes widespread adoption and community development               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> ## Significance                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> MCP represents an important step toward making AI assistants more capable and versatile by giving them          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> standardized access to external resources. This could significantly enhance the practical utility of AI systems <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> by allowing them to work with real-world data and tools in a more seamless manner.                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> The protocol essentially aims to solve the \"last mile\" problem of AI integration - making it easier for AI      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> models to actually interact with and utilize the vast ecosystem of digital tools and data sources that exist in <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> modern computing environments.                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[37m╭─\u001B[0m\u001B[37m────────────────────────────────────────────────────\u001B[0m\u001B[37m 📝 AI \u001B[0m\u001B[37m────────────────────────────────────────────────────\u001B[0m\u001B[37m─╮\u001B[0m\n",
       "\u001B[37m│\u001B[0m Based on my search, here's a comprehensive overview of Model Context Protocol (MCP):                            \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m                                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m ## What is Model Context Protocol (MCP)?                                                                        \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m                                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m Model Context Protocol (MCP) is an **open standard protocol** developed by Anthropic that serves as a           \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m standardized communication layer between AI models and external systems. It's designed to enable seamless       \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m integration and data exchange between AI assistants and various external services.                              \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m                                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m ## Key Purpose                                                                                                  \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m                                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m MCP addresses a fundamental challenge in AI development: **connecting AI models to external data sources and    \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m tools**. Instead of building custom integrations for each service, MCP provides a unified framework that allows \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m AI models to:                                                                                                   \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m                                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m - Access databases                                                                                              \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m - Interact with APIs                                                                                            \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m - Use external tools and services                                                                               \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m - Retrieve information from various data sources                                                                \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m                                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m ## How It Works                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m                                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m MCP acts as a **bridge or translation layer** that:                                                             \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m                                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m 1. **Standardizes Communication**: Provides a consistent language and protocol for data exchange                \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m 2. **Simplifies Integration**: Eliminates the need for custom connectors for each external service              \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m 3. **Enables Interoperability**: Allows different AI systems to work with the same external resources using the \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m same protocol                                                                                                   \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m                                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m ## Key Benefits                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m                                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m - **Consistency**: One protocol to rule them all - no need to learn different APIs for each service             \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m - **Efficiency**: Streamlined data access and tool usage for AI models                                          \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m - **Scalability**: Easy to add new services and tools without rebuilding integrations                           \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m - **Open Standard**: Being open-source, it promotes widespread adoption and community development               \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m                                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m ## Significance                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m                                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m MCP represents an important step toward making AI assistants more capable and versatile by giving them          \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m standardized access to external resources. This could significantly enhance the practical utility of AI systems \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m by allowing them to work with real-world data and tools in a more seamless manner.                              \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m                                                                                                                 \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m The protocol essentially aims to solve the \"last mile\" problem of AI integration - making it easier for AI      \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m models to actually interact with and utilize the vast ecosystem of digital tools and data sources that exist in \u001B[37m│\u001B[0m\n",
       "\u001B[37m│\u001B[0m modern computing environments.                                                                                  \u001B[37m│\u001B[0m\n",
       "\u001B[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Give me an overview of Model Context Protocol (MCP).\",\n",
    "            }\n",
    "        ],\n",
    "        \"files\": {},\n",
    "    }\n",
    ")\n",
    "format_messages(result[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4addd08d",
   "metadata": {},
   "source": [
    "We can see the file saved in our mock file system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "449c8ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_request.txt': 'User Request: Give me an overview of Model Context Protocol (MCP).\\n\\nThe user wants a comprehensive overview of Model Context Protocol, including what it is, its purpose, key features, and how it works.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"files\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb506b",
   "metadata": {},
   "source": [
    "Trace: \n",
    "https://smith.langchain.com/public/b03e20b4-e908-488d-84a9-8f891d17addd/r\n",
    "<!-- https://smith.langchain.com/public/1066102f-d7b3-423c-b556-006865a1d479/r -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f4ec9b-6dd5-43cf-a0ee-274b0b638c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
